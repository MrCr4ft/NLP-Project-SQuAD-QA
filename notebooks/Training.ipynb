{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "467846e1-da99-447f-820e-36abded0c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "from squad.squad_dataset import SquadDataset\n",
    "from training.model_trainer import Trainer\n",
    "from training.utils import *\n",
    "from model.QANet import QANet\n",
    "\n",
    "training_set = SquadDataset(\"./preprocessed_dataset/training_set_features.npz\", False)\n",
    "validation_set = SquadDataset(\"./preprocessed_dataset/validation_set_features.npz\", False)\n",
    "validation_set_eval = json.load(open(\"./preprocessed_dataset/validation_set_eval.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053ec185-b90a-4211-a30e-44e2410e1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_loader = data.DataLoader(\n",
    "    training_set, \n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "validation_set_loader = data.DataLoader(\n",
    "    validation_set, \n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa8c68b-b684-4d5f-a82d-c5bcc22bab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb = torch.from_numpy(np.load('./preprocessed_dataset/glove_embeddings.npz')['emb_mat']).double()\n",
    "chr_emb = torch.from_numpy(np.load('./preprocessed_dataset/char_embeddings.npz')['emb_mat']).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75fbe88-fcda-49ce-b585-a2fba5471b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"./config.json\"))\n",
    "model = QANet(word_emb, chr_emb, config).double().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85d7241-0ac0-44b1-bacc-707e0c646ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QANet(\n",
       "  (input_embedding_layer): InputEmbeddingLayer(\n",
       "    (word_embed): Embedding(83941, 300)\n",
       "    (char_embed): CharacterEmbedding(\n",
       "      (char_embeddings): Embedding(1309, 200)\n",
       "      (conv1): Conv2d(200, 200, kernel_size=(1, 5), stride=(1, 1))\n",
       "    )\n",
       "    (highway): Highway(\n",
       "      (t_gates): ModuleList(\n",
       "        (0): Linear(in_features=500, out_features=500, bias=True)\n",
       "        (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      )\n",
       "      (h_gates): ModuleList(\n",
       "        (0): Linear(in_features=500, out_features=500, bias=True)\n",
       "        (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding_encoder_layer): EncoderEmbeddingLayer(\n",
       "    (conv1d): Reshape1Dconv(\n",
       "      (conv1d): Conv1d(500, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (c_pos_encoder): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (q_pos_encoder): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cq_attention): ContextQueryAttention()\n",
       "  (model_encoder_layer): ModelEncoder(\n",
       "    (reshape_conv): Reshape1Dconv(\n",
       "      (conv1d): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (model_blocks): ModuleList(\n",
       "      (0): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (4): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (5): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (6): EncoderBlock(\n",
       "        (conv): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (conv_layer_norm): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Output(\n",
       "    (w1): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (w2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema = EMA(model, 0.9999)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3, betas=(0.8, 0.999), eps=1e-8, weight_decay=3e-7)\n",
    "cr = 1.0 / math.log(1000)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda ee: cr * math.log(ee + 1) if ee < 1000 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428c671-68a4-4b1a-bb86-0927de8faca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:19<00:00, 83.98it/s, avg_loss=6.47, batch_ce=4.92, epoch=1, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 272.79it/s, batch_ce=5.13, time=Feb-06_17-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 21.904205607476637, 'F1': 32.5156667452638}\n",
      "Saving checkpoint: model_checkpoints/epoch01_f1_32.51567_em_21.90421.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.02it/s, avg_loss=5.08, batch_ce=3.87, epoch=2, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.31it/s, batch_ce=4.02, time=Feb-06_17-20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 31.230529595015575, 'F1': 43.096097242628474}\n",
      "Saving checkpoint: model_checkpoints/epoch02_f1_43.09610_em_31.23053.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.01it/s, avg_loss=4.08, batch_ce=1.81, epoch=3, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.43it/s, batch_ce=2.96, time=Feb-06_17-36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 45.40498442367601, 'F1': 59.52451417759945}\n",
      "Saving checkpoint: model_checkpoints/epoch03_f1_59.52451_em_45.40498.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.03it/s, avg_loss=3.29, batch_ce=1.34, epoch=4, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.06it/s, batch_ce=2.83, time=Feb-06_17-53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 50.95404984423676, 'F1': 65.65826486682144}\n",
      "Saving checkpoint: model_checkpoints/epoch04_f1_65.65826_em_50.95405.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:19<00:00, 83.98it/s, avg_loss=2.93, batch_ce=1.32, epoch=5, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.56it/s, batch_ce=2.65, time=Feb-06_18-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 53.07632398753894, 'F1': 67.54032156767454}\n",
      "Saving checkpoint: model_checkpoints/epoch05_f1_67.54032_em_53.07632.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:19<00:00, 83.99it/s, avg_loss=2.7, batch_ce=0.972, epoch=6, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.43it/s, batch_ce=2.61, time=Feb-06_18-26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 53.81619937694704, 'F1': 68.65606202942605}\n",
      "Saving checkpoint: model_checkpoints/epoch06_f1_68.65606_em_53.81620.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.01it/s, avg_loss=2.53, batch_ce=1.01, epoch=7, learning_rate=[0.001], time=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.45it/s, batch_ce=2.51, time=Feb-06_18-43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 54.61448598130841, 'F1': 69.31418849278492}\n",
      "Saving checkpoint: model_checkpoints/epoch07_f1_69.31419_em_54.61449.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.02it/s, avg_loss=2.39, batch_ce=0.882, epoch=8, learning_rate=[0.001], time=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.78it/s, batch_ce=2.68, time=Feb-06_19-00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 54.94548286604361, 'F1': 69.64133319474541}\n",
      "Saving checkpoint: model_checkpoints/epoch08_f1_69.64133_em_54.94548.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 82240/82240 [16:18<00:00, 84.01it/s, avg_loss=2.28, batch_ce=0.954, epoch=9, learning_rate=[0.001], time=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5136/5136 [00:18<00:00, 273.44it/s, batch_ce=2.41, time=Feb-06_19-16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 54.94548286604361, 'F1': 69.47861040226148}\n",
      "Saving checkpoint: model_checkpoints/epoch09_f1_69.47861_em_54.94548.pth.tar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|▉| 76512/82240 [15:10<01:08, 83.90it/s, avg_loss=2.18, batch_ce=0.9, epoch=10, learning_rate=[0.001], time=F"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "trainer = Trainer(model, optimizer, \"cuda:0\", scheduler, 5.0, ema, 1, \"model_checkpoints\")\n",
    "trainer.train(10, training_set_loader, validation_set_loader, validation_set_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
